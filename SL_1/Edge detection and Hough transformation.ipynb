{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae3b602",
   "metadata": {},
   "source": [
    "# SOBEL EDGE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3b82a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def sobel_edge_detection(image):\n",
    "    # Converted colored image to gray scale based on the luminosity values of the human eyes.\n",
    "    \n",
    "    r, g, b = image[:,:,0], image[:,:,1], image[:,:,2]\n",
    "    gray_image= 0.21 * r + 0.72 * g + 0.07 * b\n",
    "    \n",
    "    # Applied Gaussian blur to the grayscale image for reducing the noises.\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (5,5), 0)\n",
    "    \n",
    "    # Defined Sobel kernels for calculating the horizontal and vertical gradients.\n",
    "    sobel_x = np.array([[-1, 0, 1],\n",
    "                        [-2, 0, 2],\n",
    "                        [-1, 0, 1]])\n",
    "\n",
    "    sobel_y = np.array([[-1, -2, -1],\n",
    "                        [0, 0, 0],\n",
    "                        [1, 2, 1]])\n",
    "    \n",
    "    # Convolved the blurred image with the Sobel kernels:\n",
    "    gradient_x = cv2.filter2D(gray_image, -1, sobel_x)\n",
    "    gradient_y = cv2.filter2D(gray_image, -1, sobel_y)\n",
    "    \n",
    "    # Calculated the magnitude of gradients.\n",
    "    gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "    \n",
    "    \n",
    "    # Normalized the gradient magnitude to the range [0, 255].\n",
    "    gradient_magnitude = np.uint8(gradient_magnitude / np.max(gradient_magnitude) * 255)\n",
    "    \n",
    "    enhanced_gradient = cv2.convertScaleAbs(gradient_magnitude, alpha=2.2, beta=1) #Enhanced edges for better visualization.\n",
    "\n",
    "    # Apply a threshold to further enhance edges\n",
    "    _, thresholded_gradient = cv2.threshold(enhanced_gradient, 21, 255, cv2.THRESH_BINARY) # Applied thresholding.\n",
    "\n",
    "    return thresholded_gradient\n",
    "\n",
    "# Resized the image for faster computation.\n",
    "image = cv2.imread('table.png')\n",
    "width = 400\n",
    "height = 300\n",
    "\n",
    "resized_image = cv2.resize(image, (width,height))\n",
    "    \n",
    "# Performed Sobel edge detection\n",
    "edge_image = sobel_edge_detection(resized_image)\n",
    "\n",
    "# Saved the result\n",
    "cv2.imwrite('edge.png', edge_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ef2d2",
   "metadata": {},
   "source": [
    "# HOUGH TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e869bf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Firstly Done Hough transform from python's inbuilt function.\n",
    "\n",
    "Hough_lines = cv2.HoughLines(edge_image, rho=1, theta=np.pi/180, threshold=292)\n",
    "\n",
    "# Drawn detected lines on the original image.\n",
    "\n",
    "output_image = np.copy(resized_image)\n",
    "\n",
    "if Hough_lines is not None:\n",
    "    for line in Hough_lines:\n",
    "        rho, theta = line[0]\n",
    "        A = np.cos(theta)\n",
    "        B = np.sin(theta)\n",
    "        x0 = A * rho\n",
    "        y0 = B * rho\n",
    "        x1 = int(x0 + 500 * (-B))\n",
    "        y1 = int(y0 + 500 * (A))\n",
    "        x2 = int(x0 - 500 * (-B))\n",
    "        y2 = int(y0 - 500 * (A))\n",
    "        cv2.line(output_image, (x1, y1), (x2, y2), (0, 0, 255), 2) # Drwan output lines with red color and thickness=2.\n",
    "\n",
    "# Saved the output image.\n",
    "cv2.imwrite('Hough_lines.png', output_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0104a42",
   "metadata": {},
   "source": [
    "# HOUGH TRANSFORMATION FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c6bbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def hough_transform(image, threshold):\n",
    "    # Defined the Hough space in (rho, theta) for getting various rho and theta for a point in the image space.\n",
    "    rows, cols = image.shape\n",
    "    diag_length = int(np.ceil(np.sqrt(rows ** 2 + cols ** 2))) # Calculated diagonal length.\n",
    "    rhos = np.linspace(-diag_length, diag_length, diag_length * 2) # Got 2*D rhos from -D to D.\n",
    "    thetas = np.deg2rad(np.arange(-90, 90, 1)) # Getting vaious thetas from -90 to 90 and converted them to radians.\n",
    "\n",
    "    # Initializing the accumulator array for setting the threshold to the values of Rho and theta.\n",
    "    accumulator = np.zeros((2 * diag_length, len(thetas)), dtype=np.uint64)\n",
    "    # In the accumulator array I represented rho by rows and thetas by columns. \n",
    "    \n",
    "    # Storing the edge points indices in the variable edge points.\n",
    "    edge_points = np.argwhere(image > 0)\n",
    "\n",
    "    # Looping through edge points and calculating the values in accumulator array for each edge point.\n",
    "    for y, x in edge_points:\n",
    "        for idx, theta in enumerate(thetas):\n",
    "            rho = int(x * np.cos(theta) + y * np.sin(theta))\n",
    "            accumulator[rho + diag_length, idx] += 1  # Used rho+D to avoid negative values of rho. \n",
    "\n",
    "    # Find lines with votes above threshold\n",
    "    lines = np.argwhere(accumulator >= threshold)    # Storing indices where the value in the accumulator array is greater than the threshold.\n",
    "\n",
    "    return lines\n",
    "\n",
    "# Read the edge image\n",
    "edge_image = cv2.imread('edge.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Applying the hough transform\n",
    "lines = hough_transform(edge_image, threshold=295)\n",
    "\n",
    "\n",
    "\n",
    "image = cv2.imread('table.png')\n",
    "\n",
    "# Visualizing the detected lines\n",
    "for rho, theta in lines:\n",
    "    # Transform the polar coordinates to Cartesian coordinates\n",
    "    \n",
    "    A = np.cos(theta)\n",
    "    B = np.sin(theta)\n",
    "    x0 = A * rho\n",
    "    y0 = B * rho\n",
    "    \n",
    "    # Extend the lines to the edges of the image\n",
    "    x1 = int(x0 + 1000 * (-B))\n",
    "    y1 = int(y0 + 1000 * (A))\n",
    "    x2 = int(x0 - 1000 * (-B))\n",
    "    y2 = int(y0 - 1000 * (A))\n",
    "    \n",
    "    # Draw the lines on the original image\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 1) # Drawn lines with red color with thickness 1.\n",
    "\n",
    "# Save the image with detected lines\n",
    "cv2.imwrite('Hough_lines_from_scratch.png', image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57bda98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
